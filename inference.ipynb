{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-11T04:23:32.754765Z",
     "start_time": "2024-06-11T04:23:32.749984Z"
    }
   },
   "source": [
    "# Select you GPU\n",
    "I_GPU = 0"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Uncomment to use autoreload\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "from omegaconf import OmegaConf\n",
    "import warnings\n",
    "from kitti360scripts.helpers.ply import read_ply, write_ply\n",
    "from torch_points3d.metrics.confusion_matrix import ConfusionMatrix\n",
    "import open3d as o3d\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "torch.cuda.set_device(I_GPU)\n",
    "DIR = os.path.dirname(os.getcwd())\n",
    "ROOT = os.path.join(DIR, \"..\")\n",
    "sys.path.insert(0, ROOT)\n",
    "sys.path.insert(0, DIR)\n",
    "\n",
    "from torch_points3d.utils.config import hydra_read\n",
    "from torch_points3d.trainer import Trainer\n",
    "from torch_points3d.datasets.segmentation.kitti360_config import KITTI360_NUM_CLASSES\n",
    "from kitti360scripts.helpers.ply import read_ply, write_ply"
   ],
   "id": "ce6a030b78a9e687"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set your parameters\n",
    "DATA_ROOT = '/home/jupyter/datasphere/project/KITTI-360'\n",
    "checkpoint_dir = '/home/jupyter/datasphere/project'\n",
    "result_dir = '/home/jupyter/datasphere/project/metrics'\n",
    "model_name = 'Res16UNet34-PointPyramid-early-cityscapes-interpolate'  # adapt if you use another model in your checkpoint\n",
    "split = 'val'                                                         # 'test' set will produce data for submission to the KITTI-360 3D semantic segmentation benchmark\n",
    "n_votes = 1                                                           # number of inferences per cylindrical sample. For multi-inference voting with inference-time augmentation\n",
    "sample_res = 1                                                        # saptial resolution of inference cylinder samples. Set to 3m for slower inference with +0.2 mIoU, roughly\n",
    "batch_size = 8                                                        # increase if your device allows it\n",
    "full_res = True                                                       # predictions will be made on the raw point cloud, at full resolution\n",
    "num_workers = 4                                                       # increase if your machine allows it\n",
    "exp_name = None                                                       # you may give a name to the experiment\n",
    "exp_name = f'{model_name}_{split}_votes-{n_votes}_sample_res-{sample_res}' if exp_name is None else exp_name"
   ],
   "id": "f647995ce60fc7e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f'Inference on KITTI360 exp={exp_name}')\n",
    "\n",
    "# These are the arguments passed to Hydra. You could run the same thing \n",
    "# from CLI using `eval.py` with the command `python eval.py [...]`\n",
    "overrides = [\n",
    "    f'model_name={model_name}',\n",
    "    f'checkpoint_dir={checkpoint_dir}',\n",
    "    f'voting_runs={n_votes}',\n",
    "    f'tracker_options.full_res={full_res}',\n",
    "    f'tracker_options.make_submission={split == \"test\"}',\n",
    "    'precompute_multi_scale=False',\n",
    "    f'num_workers={num_workers}',\n",
    "    f'batch_size={batch_size}',\n",
    "    f'cuda={I_GPU}',\n",
    "    'weight_name=latest',\n",
    "    f'+data.eval_sample_res={sample_res}',\n",
    "    f'+data.dataroot={DATA_ROOT}',\n",
    "    f'+data.mini={True}',\n",
    "]\n",
    "\n",
    "# Parse the arguments with Hydra and OmegaConf\n",
    "cfg = hydra_read(overrides, config_name='eval')\n",
    "OmegaConf.set_struct(cfg, False)"
   ],
   "id": "f003ae35b66dacd8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def downsample_ply(ply_path, out_path, voxel_size=0.1):\n",
    "    ply = read_ply(ply_path)\n",
    "    points = np.array((ply['x'], ply['y'], ply['z'])).T\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size=voxel_size)\n",
    "    points_down = np.asarray(pcd_down.points)\n",
    "    # select all the points from ply that are in points_down\n",
    "    mask = np.isin(points, points_down).all(axis=1)\n",
    "    # ply_down = {k: ply[k][mask] for k in ply.dtype.names}\n",
    "    write_ply(out_path, [ply[k][mask] for k in ply.dtype.names], [k for k in ply.dtype.names])"
   ],
   "id": "485f880e1b8e5de5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ply_path = '/home/jupyter/datasphere/project/KITTI-360/kitti360mm/raw/data_3d_semantics/2013_05_28_drive_0000_sync/static/0000000372_0000000610.ply'\n",
    "ply_path2 = '/home/jupyter/datasphere/project/KITTI-360/kitti360mm/raw/data_3d_semantics/2013_05_28_drive_0000_sync/static/0000000002_0000000385.ply'\n",
    "downsample_ply(ply_path, ply_path, voxel_size=0.2)\n",
    "downsample_ply(ply_path2, ply_path2, voxel_size=0.2)\n",
    "!rm -rf /home/jupyter/datasphere/project/KITTI-360/kitti360mm/processed"
   ],
   "id": "69e877f8a837ebf3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def dva_inference(cfg):\n",
    "    # Create the Trainer instance from your checkpoint\n",
    "    trainer = Trainer(cfg)\n",
    "        \n",
    "    # Update the val and test transforms to match train transforms for \n",
    "    # inference-time augmentation\n",
    "    trainer._dataset.test_dataset[0].transform = trainer._dataset.train_dataset.transform\n",
    "    if trainer._model.is_multimodal:\n",
    "        trainer._dataset.test_dataset[0].transform_image = trainer._dataset.train_dataset.transform_image\n",
    "        trainer._dataset.test_dataset[0].transform_image.transforms[3].use_coverage = False\n",
    "        trainer._dataset.test_dataset[0].transform_image.transforms[3].credit = int(1408 * 376 * 4 * 2)\n",
    "        \n",
    "        # Run inference\n",
    "    trainer.eval(stage_name=split)\n",
    "    cm = trainer._tracker._full_confusion_matrix\n",
    "    \n",
    "    if split != 'test':\n",
    "        print(f'  mIoU={cm.get_average_intersection_union() * 100:0.2f}')\n",
    "        print(f'  OA={cm.get_overall_accuracy() * 100:0.2f}')\n",
    "    return cm.get_average_intersection_union() * 100"
   ],
   "id": "841e8939d3d77c22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from unimodal_hdmapnet import eval_semantic\n",
    "\n",
    "def my_inference():\n",
    "    ground_truth = read_ply(ply_path2)['semantic']\n",
    "    semantic = eval_semantic()\n",
    "    matrix = ConfusionMatrix(KITTI360_NUM_CLASSES)\n",
    "    return matrix.count_predicted_batch(ground_truth, semantic)"
   ],
   "id": "19e70abfedd90ff5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
